{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandobox for developing bounding box detectors for orthomosaics\n",
    "#### input: an orthomosaic and a YOLOv5 model\n",
    "#### output: multi-polygon (bounding boxes) shapefile with bounding box class and probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start timestamp in UTC: 2022-12-07 14:18:09.250990\n"
     ]
    }
   ],
   "source": [
    "import os, glob, shutil\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")      \n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "#from ocifs import OCIFileSystem\n",
    "#import fsspec\n",
    "from datetime import datetime, timedelta\n",
    "from osgeo import gdal, ogr, osr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "#import logging\n",
    "import os\n",
    "import sys\n",
    "import tkinter as tk\n",
    "import tkinter.filedialog as fd\n",
    "\n",
    "# for inference part\n",
    "import torch\n",
    "import cv2\n",
    "#from cv2 import cv2\n",
    "import PIL.Image as Image\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "\n",
    "# for parsing part\n",
    "from utils.tools import yolo2xy\n",
    "\n",
    "\n",
    "gdal_utils_path=os.getcwd()+\"/utils/\"\n",
    "modelZoo_path=os.getcwd()+\"/model_zoo/\"\n",
    "yolov5_repo_path=os.getcwd()+\"/yolov5\"\n",
    "\n",
    "\n",
    "print(\"Start timestamp in UTC: {}\".format(str(datetime.utcnow())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def directory_mode():\n",
    "    root = tk.Tk()\n",
    "    orthos_to_process = []\n",
    "    directory = fd.askdirectory(parent=root, title=\"Choose directory\")\n",
    "    input_orthos_to_process = glob.glob(directory + \"/**/*.tif\", recursive=True)\n",
    "    for i in input_orthos_to_process:\n",
    "        if \"FSCT_output\" not in i:\n",
    "            orthos_to_process.append(i)\n",
    "    root.destroy()\n",
    "    return orthos_to_process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MAIN PARAMETERS\n",
    "tile_size_m=32\n",
    "buffer_size_m=2\n",
    "format_tiles=\"GTiff\"\n",
    "GPU = False\n",
    "\n",
    "# define inference parameters\n",
    "img_size= 640\n",
    "conf_threshold=0.4 # confidence threshold to remove bounding boxes from inference \n",
    "\n",
    "intile=1 # tile inner buffer in meters to remove edge artifacts                                       \n",
    "iou_thresh=0.75 # used to clea-up duplicate boxes. It is the maximum threshold above which two intersecting bounding boxes are considered as the same one and thus the one with largest probability is selected\n",
    "model_name=\"treeSpecies_detector_s_im640_batch20_best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>class_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bo</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spruce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deciduous</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name  class_code\n",
       "0         bo           0\n",
       "1     spruce           1\n",
       "2       pine           2\n",
       "3  deciduous           3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define classes\n",
    "d = {'class_name': [\"bo\",\"spruce\",\"pine\",\"deciduous\"], 'class_code': [0,1,2,3]}\n",
    "classes = pd.DataFrame(data=d)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OCI-related\n",
    "\n",
    "#logging.getLogger(\"ocifs\").setLevel(logging.ERROR)\n",
    "#logging.getLogger(\"yolov5\").setLevel(logging.ERROR)\n",
    " \n",
    "#os.system(\"conda-unpack\")\n",
    "\n",
    "#def copyFileRemotely(fileFrom,fileTo):\n",
    "#    fs = OCIFileSystem()\n",
    "#    input = open(fileFrom,\"rb\")\n",
    "#    output = fs.open(fileTo,\"wb\")\n",
    "#    output.write(input.read())\n",
    "#    output.close()\n",
    "#    input.close()\n",
    "    \n",
    "#def copyFileLocally(fileFrom,fileTo):\n",
    "#    fs = OCIFileSystem()\n",
    "#    input = fs.open(fileFrom)\n",
    "#    output = open(fileTo,\"wb\")\n",
    "#    output.write(input.read())\n",
    "#    output.close()\n",
    "#    input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## parse input parameters\n",
    "#for item1 in sys.argv[1:]:\n",
    "#    item = item1.split('=',2)\n",
    "#    os.environ[item[0]]=item[1]\n",
    "\n",
    "#input_location = os.environ.get(\"OBJ_INPUT_LOCATION\")\n",
    "#output_location = os.environ.get(\"OBJ_OUTPUT_LOCATION\")\n",
    "\n",
    "#if input_location is not None:\n",
    "#    print(\"Input location: \"+ input_location)\n",
    "#else:\n",
    "#    print(\"Missing input location (OBJ_INPUT_LOCATION)\")\n",
    "#    exit\n",
    "    \n",
    "#if output_location is not None:\n",
    "#    print(\"Output location: \"+ output_location)\n",
    "#else:\n",
    "#    print(\"Missing ouput location (OBJ_OUTPUT_LOCATION)\")\n",
    "#    exit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if executed as a job, the conda pack is in /condapack folder and the artifact in decompressed_artifact\n",
    "#   decompressed_artifact/nibio/inference.py\n",
    "#   /home/datascience/condapack/yolov5/lib/python3.8/site-packages/torch/hub.py\n",
    "\n",
    "#JOB_RUN_OCID_KEY = \"JOB_RUN_OCID\"\n",
    "#job_run_ocid = os.environ.get(JOB_RUN_OCID_KEY, \"UNDEFINED\")\n",
    "\n",
    "# to work in jobs\n",
    "#dirname = os.path.dirname(os.path.abspath(__file__))\n",
    "#print(\"dirname= \" + dirname)\n",
    "\n",
    "### create a temporary directory with a tiles_dir subdirectoruy\n",
    "#local_temp=\"/home/datascience/tmp/\"\n",
    "#if not os.path.exists(local_temp):\n",
    "#    os.makedirs(local_temp)    \n",
    "    \n",
    "#tiles_dir_temp=local_temp+\"tiles_dir/\"\n",
    "#if not os.path.exists(tiles_dir_temp):\n",
    "#    os.makedirs(tiles_dir_temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\Avskakalia_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\Brattaas_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\dahl_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\Ersgaard_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\huuse_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\Jonsonhaugen_1st_ortho.tif',\n",
       " 'C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\\\Sustad_1st_ortho.tif']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get list of orthomosaics to process\n",
    "orthos_to_process = directory_mode()\n",
    "orthos_to_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\Avskakalia_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Avskakalia_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 24 tiles\n",
      "    Remaining 130 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "4 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "11 % done!\n",
      "12 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "18 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "27 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "35 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "42 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "50 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "58 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "65 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "73 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "82 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "88 % done!\n",
      "89 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "96 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Avskakalia_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Avskakalia_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\Brattaas_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Brattaas_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 22 tiles\n",
      "    Remaining 110 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Brattaas_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Brattaas_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\dahl_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/dahl_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 11 tiles\n",
      "    Remaining 99 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/dahl_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/dahl_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\Ersgaard_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Ersgaard_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 19 tiles\n",
      "    Remaining 80 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "26 % done!\n",
      "27 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "49 % done!\n",
      "50 % done!\n",
      "51 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "73 % done!\n",
      "74 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Ersgaard_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Ersgaard_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\huuse_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/huuse_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 32 tiles\n",
      "    Remaining 234 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "5 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "11 % done!\n",
      "12 % done!\n",
      "13 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "18 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "26 % done!\n",
      "27 % done!\n",
      "28 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "34 % done!\n",
      "35 % done!\n",
      "36 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "41 % done!\n",
      "42 % done!\n",
      "43 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "49 % done!\n",
      "50 % done!\n",
      "51 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "57 % done!\n",
      "58 % done!\n",
      "59 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "64 % done!\n",
      "65 % done!\n",
      "66 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "72 % done!\n",
      "73 % done!\n",
      "74 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "82 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "87 % done!\n",
      "88 % done!\n",
      "89 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "95 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "98 % done!\n",
      "99 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/huuse_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/huuse_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\Jonsonhaugen_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Jonsonhaugen_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 20 tiles\n",
      "    Remaining 90 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "1 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "27 % done!\n",
      "28 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "34 % done!\n",
      "35 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "41 % done!\n",
      "42 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "58 % done!\n",
      "59 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "65 % done!\n",
      "66 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "72 % done!\n",
      "73 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "99 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Jonsonhaugen_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Jonsonhaugen_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "Started with: C:/Users/stpu/snowBreakYOLO/predictLeafOFF\\Sustad_1st_ortho.tif\n",
      "Loading orthomosaic and extracting some metadata\n",
      "Generating orthomosaic boundary file\n",
      "0...10...20...30...40...50...60...70...80...90...Creating output C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Sustad_1st_ortho_boundary.shp of format ESRI Shapefile.\n",
      "100 - done.\n",
      "\n",
      "Tiling the orthomosaic\n",
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n",
      "\n",
      "Removing boundary tiles\n",
      "    Removing 18 tiles\n",
      "    Remaining 72 tiles\n",
      "Finished with ortho tiling part ..................................................................................\n",
      "Starting YOLO inference (this might take a while without GPU)\n",
      "Predicting using this model: C:\\Users\\stpu\\snowBreakYOLO/model_zoo//treeSpecies_detector_s_im640_batch20_best.pt\n",
      "\n",
      "Finished YOLO inference ..........................................................................................\n",
      "Starting to parse the predicted bounding boxes from image to map space\n",
      "0 % done!\n",
      "2 % done!\n",
      "4 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "9 % done!\n",
      "11 % done!\n",
      "13 % done!\n",
      "15 % done!\n",
      "17 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "22 % done!\n",
      "24 % done!\n",
      "26 % done!\n",
      "28 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "33 % done!\n",
      "35 % done!\n",
      "37 % done!\n",
      "39 % done!\n",
      "41 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "46 % done!\n",
      "48 % done!\n",
      "50 % done!\n",
      "52 % done!\n",
      "54 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "59 % done!\n",
      "61 % done!\n",
      "63 % done!\n",
      "65 % done!\n",
      "67 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "72 % done!\n",
      "74 % done!\n",
      "76 % done!\n",
      "78 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "83 % done!\n",
      "85 % done!\n",
      "87 % done!\n",
      "89 % done!\n",
      "91 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "96 % done!\n",
      "98 % done!\n",
      "converting geoJSON.............\n",
      "ogr2ogr -f GeoJSON C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Sustad_1st_ortho_predictions.json C:/Users/stpu/snowBreakYOLO/predictLeafOFF/Sustad_1st_ortho_predictions.shp\n",
      "Finished file.........................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n",
      "......................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "for ortho_path in orthos_to_process:\n",
    "    # 1 - SETUP DIRS\n",
    "    print(\"Started with: \"+ ortho_path)\n",
    "    ortho_name=Path(ortho_path).stem # ortho name      \n",
    "    temp= os.path.dirname(ortho_path)\n",
    "    if not os.path.exists(temp):\n",
    "        os.makedirs(temp)    \n",
    "    tiles_temp=temp+\"/tiles_dir_\"+ortho_name+\"/\"\n",
    "    if not os.path.exists(tiles_temp):\n",
    "        os.makedirs(tiles_temp)    \n",
    "    temp_predict=tiles_temp+\"predict\"\n",
    "    if not os.path.exists(temp_predict):\n",
    "        os.makedirs(temp_predict)\n",
    "    temp_dir_predict_out=temp_predict+\"/out\"\n",
    "    temp_dir_labels=temp_dir_predict_out+\"/labels\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 2 - GET RASTER METADATA\n",
    "    print(\"Loading orthomosaic and extracting some metadata\")\n",
    "    ## Get pixel resolution (in meters) and tile size in pixels\n",
    "    src_ds = gdal.Open(ortho_path)\n",
    "    _, xres, _, _, _, yres  = src_ds.GetGeoTransform() # get pixel size in meters\n",
    "    tile_size_px= round(tile_size_m/abs(xres)) # calculate the tile size in pixels\n",
    "    ## Get EPSG code\n",
    "    proj = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
    "    EPSG_code= proj.GetAttrValue('AUTHORITY',1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 3 - GENERATE ORTHOMOSAIC BOUNDARY SHAPEFILE\n",
    "    print(\"Generating orthomosaic boundary file\")\n",
    "    ## Define name for boundary shapefile\n",
    "    shape_path=temp+\"/\"+ortho_name+\"_boundary.shp\"\n",
    "    ## Run gdal_polygonize.py to get boundaries from alpha band (band 4)\n",
    "    #%run /home/datascience/cnn_wheel_ruts/gdal_polygonize.py $ortho_path -b 4 $shape_path\n",
    "    command_polygonize =\"python \"+ gdal_utils_path+\"gdal_polygonize.py \"+ ortho_path + \" -b 4 \" + shape_path\n",
    "    print(os.popen(command_polygonize).read())\n",
    "    ## Select polygon that has DN equal to 255, indicating the area where drone data is available for\n",
    "    polys = gpd.read_file(shape_path)\n",
    "    polys[polys['DN']==255]#.to_file(shape_path)\n",
    "    polys.to_file(shape_path)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 4 - TILING THE ORTHOMOSAIC\n",
    "    print(\"Tiling the orthomosaic\")\n",
    "    ## Define buffer size and calculate the size of tiles excluding buffer\n",
    "    tile_size_px= round(tile_size_m/abs(xres))\n",
    "    buffer_size_px= round(buffer_size_m/abs(xres))\n",
    "    tileIndex_name=ortho_name+\"_tile_index\" # define name for output tile index shapefile\n",
    "    ## Run gdal_retile.py (can take some minutes) \n",
    "    if format_tiles==\"PNG\":\n",
    "        command_retile = \"python \"+ gdal_utils_path +\"gdal_retile.py -targetDir \" + tiles_temp + \" \" + ortho_path+ \" -overlap \" + str(buffer_size_px) + \" -ps \"+str(tile_size_px) + \" \" + str(tile_size_px) + \" -of PNG -co WORLDFILE=YES -tileIndex \"+ tileIndex_name + \" -tileIndexField ID\"\n",
    "    if format_tiles==\"GTiff\":\n",
    "        command_retile = \"python \"+ gdal_utils_path+ \"gdal_retile.py -targetDir \" + tiles_temp + \" \" + ortho_path+ \" -overlap \" + str(buffer_size_px) + \" -ps \"+str(tile_size_px) + \" \" + str(tile_size_px) + \" -of GTiff -tileIndex \"+ tileIndex_name + \" -tileIndexField ID\"\n",
    "    print(os.popen(command_retile).read())\n",
    "    \n",
    "    \n",
    "    # 5 - KEEP ONLY TILES WITHIN THE ORTHOMOSAIC BOUNDARY\n",
    "    print(\"Removing boundary tiles\")\n",
    "    ## Load boundary\n",
    "    boundary = gpd.read_file(shape_path) #  read in the shapefile using geopandas\n",
    "    boundary = boundary.geometry.unary_union #union of all geometries in the GeoSeries\n",
    "    ## Load tiles shapefile\n",
    "    tiles = gpd.read_file(tiles_temp+ \"/\"+ortho_name+\"_tile_index.shp\")\n",
    "    ## Select all tiles that are not within the boundary polygon\n",
    "    tiles_out = tiles[~tiles.geometry.within(boundary)]\n",
    "    ## Create a series for each file format with all names of files to be removed\n",
    "    names_tiles_out = [os.path.splitext(x)[0] for x in tiles_out['ID']] # get names without extension\n",
    "\n",
    "    if format_tiles==\"PNG\":\n",
    "        pngs_delete=[tiles_dir+ \"/\"+sub + '.png' for sub in names_tiles_out] # add .png extension\n",
    "        xml_delete=[tiles_dir+ \"/\" +sub + '.png.tmp.aux.xml' for sub in names_tiles_out] # ...\n",
    "        wld_delete=[tiles_dir+ \"/\"+sub + '.png.wld' for sub in names_tiles_out] #...\n",
    "        ## Delete files\n",
    "        for f in pngs_delete: # delete png files\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "        for f in xml_delete:  # delete xmls files\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "        for f in wld_delete:  # delete world files\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "\n",
    "    if format_tiles==\"GTiff\":\n",
    "        \n",
    "\n",
    "        gtiffs_delete=[tiles_temp+ \"/\"+sub + '.tif' for sub in names_tiles_out] # add .png extension\n",
    "        for f in gtiffs_delete: # delete png files\n",
    "            if os.path.exists(f):\n",
    "                os.remove(f)\n",
    "        print(\"    Removing \" +str(len(gtiffs_delete))+\" tiles\")\n",
    "        print(\"    Remaining \" +str(len(tiles)-len(gtiffs_delete))+\" tiles\")       \n",
    "    print(\"Finished with ortho tiling part ..................................................................................\")\n",
    "\n",
    "    \n",
    "    \n",
    "    # 6 - YOLO INFERENCE\n",
    "    print(\"Starting YOLO inference (this might take a while without GPU)\")\n",
    "    ## define model weights file\n",
    "    model_weights =modelZoo_path+\"/\"+model_name\n",
    "    print(\"Predicting using this model: \" + model_weights)   \n",
    "    ## run inference\n",
    "    if GPU == True:\n",
    "        command_predict = \"python \"+ yolov5_repo_path+\"/detect.py --source \" + tiles_temp + \" --weights \" + model_weights + \" --img \" + str(img_size) + \" --name \" + temp_dir_predict_out + \" --save-txt --save-conf --nosave --conf-thres \" + str(conf_threshold) + \" --device=0\" + \" --agnostic\"\n",
    "        #%run /home/datascience/conda/yolov5/yolov5/detect.py --source $temp_dir_predict --weights $model_weights --img 640  --name $temp_dir_predict --save-txt --save-conf --nosave --conf-thres=0.4 --device=0\n",
    "    else:\n",
    "        command_predict = \"python \"+ yolov5_repo_path+ \"/detect.py --source \" + tiles_temp + \" --weights \" + model_weights + \" --img \" + str(img_size) + \" --name \" + temp_dir_predict_out + \" --save-txt --save-conf --nosave --conf-thres \" + str(conf_threshold) + \" --agnostic\"\n",
    "        # %run /home/datascience/conda/yolov5/yolov5/detect.py --source $temp_dir_predict --weights $model_weights --img 640  --name $temp_dir_predict --save-txt --save-conf --nosave --conf-thres=0.4\n",
    "\n",
    "    print(os.popen(command_predict).read())\n",
    "    print(\"Finished YOLO inference ..........................................................................................\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 7 - PARSING FROM IMAGE SPACE TO MAP SPACE\n",
    "    print(\"Starting to parse the predicted bounding boxes from image to map space\")\n",
    "    gtiffs = glob.glob(tiles_temp + \"/*.tif\")\n",
    "    labels = glob.glob(temp_dir_labels + \"/*.txt\")\n",
    "\n",
    "    tile_index_shape = glob.glob(tiles_temp + \"/\" + \"*tile_index*\") \n",
    "    for l in tile_index_shape:\n",
    "        l\n",
    "\n",
    "    tile_index_temp = tiles_temp+ \"/\" + os.path.splitext(os.path.basename(l))[0] + \".shp\"\n",
    "    tile_index = gpd.read_file(tile_index_temp) # read tile index shapefile\n",
    "\n",
    "    ## Get pixel resolution (in meters) and tile size in pixels\n",
    "    src_ds = gdal.Open(gtiffs[0]) # get raster datasource\n",
    "    _, xres, _, _, _, yres  = src_ds.GetGeoTransform() # get pixel size in meters\n",
    "    tile_size_m=round(src_ds.RasterXSize*xres)\n",
    "    tile_size_px= round(tile_size_m/abs(xres)) # calculate the tile size in pixels\n",
    "    ## Get EPSG code\n",
    "    proj = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
    "    EPSG_code= proj.GetAttrValue('AUTHORITY',1)\n",
    "    \n",
    "    # iterate through each txt file and trhough each row (bounding box) within a txt file\n",
    "    all_bboxes = None\n",
    "    iter_all=0\n",
    "    for lab in range(len(labels)):\n",
    "        print(str(round(lab/len(labels)*100))+\" % done!\")\n",
    "        # Define one label file and select the corresponding geotiff image\n",
    "        label_file=labels[lab]\n",
    "        label_file_name=Path(label_file).stem # ortho name\n",
    "        for p in gtiffs:\n",
    "            if Path(p).stem ==label_file_name:\n",
    "                gtiff_file=p\n",
    "\n",
    "        #print(\"debug label file = \" + label_file)\n",
    "        #print(\"debug tif file = \" + gtiff_file)\n",
    "\n",
    "        # determing image witdth and height\n",
    "        r = gdal.Open(gtiff_file)\n",
    "        img_width=r.RasterXSize\n",
    "        img_height=r.RasterYSize\n",
    "\n",
    "        # Convert from yolo coordinates to x1, y1, x2, y2,\n",
    "        # WARNING : I had to modify yolo2xyx with ocifs + other things\n",
    "        coords = yolo2xy(label_file, img_width, img_height) # class, x1, y1, x2, y2, probability \n",
    "\n",
    "        # Convert from image to geographical coordinates\n",
    "        ## select tile polygon (from tile index shapefile) that corresponds to the label_file_name\n",
    "        # the other files are required by the gpd readfile\n",
    "\n",
    "\n",
    "        # tile_index is <class 'geopandas.geodataframe.GeoDataFrame'>\n",
    "        one_tile=tile_index[tile_index['ID']==label_file_name+\".tif\"] # Select tile in tile_index that has ID equal to label_file_name\n",
    "\n",
    "        ## get tile bounding box geographical coordinates (UTM)\n",
    "        one_tile_XminUTM=one_tile.total_bounds[0]\n",
    "        one_tile_YminUTM=one_tile.total_bounds[1]\n",
    "        one_tile_XmaxUTM=one_tile.total_bounds[2]\n",
    "        one_tile_YmaxUTM=one_tile.total_bounds[3]\n",
    "\n",
    "        ## take inner buffer equal to the buffer_size_m \n",
    "        one_tile_innerB= one_tile\n",
    "        one_tile_innerB['geometry'] = one_tile_innerB.geometry.buffer(-intile)\n",
    "\n",
    "        ## get inner tile bounding boxes\n",
    "        one_tile_inner_XminUTM=one_tile_innerB.total_bounds[0]\n",
    "        one_tile_inner_YminUTM=one_tile_innerB.total_bounds[1]\n",
    "        one_tile_inner_XmaxUTM=one_tile_innerB.total_bounds[2]\n",
    "        one_tile_inner_YmaxUTM=one_tile_innerB.total_bounds[3]\n",
    "\n",
    "        # Now iterate through each bounding box and assign UTM coordinates and create a shapefile\n",
    "        bboxes_tile = None\n",
    "        for i in coords:\n",
    "            # print(\"inside coords\")\n",
    "            # Convert bounding box coordinates from image to geographical coords\n",
    "            X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
    "            Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m\n",
    "            X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
    "            Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m\n",
    "\n",
    "            # skip bounding box if its centroid is NOT within the inner tile (removing the overlap)\n",
    "            X_UTM= (X1_UTM+X2_UTM)/2\n",
    "            Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
    "            if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
    "                #print(\"continue break\")\n",
    "                continue\n",
    "\n",
    "            #print(\"over continue break\")    \n",
    "\n",
    "            # Create polygon shape from geographical coords\n",
    "            lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
    "            lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
    "            polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "            crs = {'init': 'epsg:'+EPSG_code}\n",
    "            data= {'class': [i[0]], 'prob': [i[5]]}\n",
    "            bbox = gpd.GeoDataFrame(data, crs=crs, geometry=[polygon_geom])\n",
    "\n",
    "            if (bboxes_tile is None):\n",
    "                bboxes_tile = bbox\n",
    "            else:\n",
    "                bboxes_tile = bboxes_tile.append(bbox)\n",
    "\n",
    "        # cleanup boxes (removing overlapping ones)\n",
    "        if bboxes_tile is not None:\n",
    "            #clean_boxes = bboxes_tile #cleanUp_boudingBoxes(bboxes_tile, iou_thresh)\n",
    "            if (all_bboxes is None):\n",
    "                all_bboxes = bboxes_tile\n",
    "            else :\n",
    "                all_bboxes = all_bboxes.append(bboxes_tile)\n",
    "                \n",
    "                \n",
    "    # convert class names\n",
    "    all_bboxes.loc[all_bboxes['class']==0,'class_name']='bo'\n",
    "    all_bboxes.loc[all_bboxes['class']==1,'class_name']='spruce'\n",
    "    all_bboxes.loc[all_bboxes['class']==2,'class_name']='pine'\n",
    "    all_bboxes.loc[all_bboxes['class']==3,'class_name']='deciduous'\n",
    "    all_bboxes= all_bboxes.drop(['class'],axis=1)\n",
    "    \n",
    "    # export shapefile\n",
    "    all_bboxes.to_file(temp + \"/\" + ortho_name + \"_predictions.shp\", driver='ESRI Shapefile') # turn this off if it's not needed\n",
    "    \n",
    "    # convert to geoJSON\n",
    "    \n",
    "    # convert to geoJSON\n",
    "    print(\"converting geoJSON.............\")\n",
    "    input_shp = temp + \"/\" + ortho_name + \"_predictions.shp\"\n",
    "    output_geoJson = temp + \"/\" + ortho_name + \"_predictions.json\"\n",
    "    cmd = \"ogr2ogr -f GeoJSON \"  + output_geoJson +\" \" + input_shp\n",
    "    print(cmd)\n",
    "    subprocess.call(cmd , shell=True)       \n",
    "    print(\"Finished file.........................................................................................................\")\n",
    "    print(\"......................................................................................................................\")\n",
    "    print(\"......................................................................................................................\")\n",
    "    print(\"......................................................................................................................\")\n",
    "    \n",
    "    #shutil.rmtree(tiles_temp)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

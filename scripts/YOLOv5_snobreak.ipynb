{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e83ec76e",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47111bb2",
   "metadata": {},
   "source": [
    "# 1 -Setup the environment (this is required only the first time that the environment is setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68fe386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/ultralytics/yolov5  # clone\n",
    "#cd yolov5\n",
    "#pip install -r requirements.txt  # install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b57f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if gdal, geopandas, rasterio, cv2 are installed (if not then install them with the following commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "942adf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae7e24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gdal is not installed then run this\n",
    "#%conda install -c conda-forge gdal=3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "4823b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas fiona shapely pyproj rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8f4fb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall rtree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5d121017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160c474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install geopandas==0.10.2\n",
    "#!pip install rasterio==1.2.10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8ec0d",
   "metadata": {},
   "source": [
    "# 2 - load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc31bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob,shutil\n",
    "from osgeo import gdal, ogr, osr\n",
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "from cv2 import cv2\n",
    "# load my own functions\n",
    "os.chdir(\"/home/datascience/utils\")\n",
    "from tools import tile_ortho, yolo2xy, cleanUp_boudingBoxes, mosaic_yoloPred_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7df8a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d2729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99376aa4",
   "metadata": {},
   "source": [
    "# 3 - Split large orthomosaic into small tiles (32 meters side)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc3c7dc",
   "metadata": {},
   "source": [
    "### Define parameters for splitting orthomosaic into tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de21b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho_path= \"/home/datascience/yolov5_snowdamage/data/7661_ortho.tif\"\n",
    "tile_size_m= 32 # length of the side of each tile in meters\n",
    "buffer_size_m= 3 # size of buffer around each tile "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa268dc",
   "metadata": {},
   "source": [
    "Get orthomosaic metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ab4e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get name of the orthomosaic/drone project and the path where it's stored\n",
    "ortho_name=Path(ortho_path).stem # ortho name\n",
    "ortho_folder_path=os.path.dirname(ortho_path) # get path name for the folder where the orthomosaic is stored\n",
    "## Get pixel resolution (in meters) and tile size in pixels\n",
    "src_ds = gdal.Open(ortho_path) # get raster datasource\n",
    "_, xres, _, _, _, yres  = src_ds.GetGeoTransform() # get pixel size in meters\n",
    "tile_size_px= round(tile_size_m/abs(xres)) # calculate the tile size in pixels\n",
    "## Get EPSG code\n",
    "proj = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
    "EPSG_code= proj.GetAttrValue('AUTHORITY',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e636da7",
   "metadata": {},
   "source": [
    "### Run tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4047fb72",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bce1b55cd6f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtile_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mortho_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtile_size_m\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuffer_size_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GTiff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/utils/tools.py\u001b[0m in \u001b[0;36mtile_ortho\u001b[0;34m(ortho_path, tile_size_m, buffer_size_m, format_tiles)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/datascience/utils/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mcommand_polygonize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gdal_polygonize.py \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mortho_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" -b 4 \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mshape_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_polygonize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m## Select polygon that has DN equal to 255, indicating the area where drone data is available for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mpolys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tile_ortho(ortho_path,tile_size_m,buffer_size_m, \"GTiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7f498f",
   "metadata": {},
   "source": [
    "# 4 - Inference on tiled pngs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f26b11",
   "metadata": {},
   "source": [
    "Define confidence threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70609a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres=0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20de70",
   "metadata": {},
   "source": [
    "Create output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e7c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output path\n",
    "tiles_dir=os.path.dirname(ortho_path)+\"/tiles_dir\"\n",
    "output_dir= tiles_dir+'/predictions'\n",
    "# create folder if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda738e2",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56586b8a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "/home/datascience/yolov5/detect.py --source $tiles_dir --weights /home/datascience/yolov5_snowdamage/model/best.pt --img 640 --name $output_dir --save-txt --save-conf --nosave --conf-thres=0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f95007f",
   "metadata": {},
   "source": [
    "# 5 - Convert all predictions from image to map coords and merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde29bdc",
   "metadata": {},
   "source": [
    "Define where YOLO predictions are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "962a6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dir=output_dir+\"/labels\"\n",
    "intile=1\n",
    "iou_thresh=0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb38a6",
   "metadata": {},
   "source": [
    "### Parse and mosaic YOLO prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3236fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 % done!\n",
      "0 % done!\n",
      "1 % done!\n",
      "1 % done!\n",
      "2 % done!\n",
      "2 % done!\n",
      "3 % done!\n",
      "3 % done!\n",
      "4 % done!\n",
      "4 % done!\n",
      "4 % done!\n",
      "5 % done!\n",
      "5 % done!\n",
      "6 % done!\n",
      "6 % done!\n",
      "7 % done!\n",
      "7 % done!\n",
      "8 % done!\n",
      "8 % done!\n",
      "8 % done!\n",
      "9 % done!\n",
      "9 % done!\n",
      "10 % done!\n",
      "10 % done!\n",
      "11 % done!\n",
      "11 % done!\n",
      "12 % done!\n",
      "12 % done!\n",
      "12 % done!\n",
      "13 % done!\n",
      "13 % done!\n",
      "14 % done!\n",
      "14 % done!\n",
      "15 % done!\n",
      "15 % done!\n",
      "15 % done!\n",
      "16 % done!\n",
      "16 % done!\n",
      "17 % done!\n",
      "17 % done!\n",
      "18 % done!\n",
      "18 % done!\n",
      "19 % done!\n",
      "19 % done!\n",
      "19 % done!\n",
      "20 % done!\n",
      "20 % done!\n",
      "21 % done!\n",
      "21 % done!\n",
      "22 % done!\n",
      "22 % done!\n",
      "23 % done!\n",
      "23 % done!\n",
      "23 % done!\n",
      "24 % done!\n",
      "24 % done!\n",
      "25 % done!\n",
      "25 % done!\n",
      "26 % done!\n",
      "26 % done!\n",
      "27 % done!\n",
      "27 % done!\n",
      "27 % done!\n",
      "28 % done!\n",
      "28 % done!\n",
      "29 % done!\n",
      "29 % done!\n",
      "30 % done!\n",
      "30 % done!\n",
      "31 % done!\n",
      "31 % done!\n",
      "31 % done!\n",
      "32 % done!\n",
      "32 % done!\n",
      "33 % done!\n",
      "33 % done!\n",
      "34 % done!\n",
      "34 % done!\n",
      "35 % done!\n",
      "35 % done!\n",
      "35 % done!\n",
      "36 % done!\n",
      "36 % done!\n",
      "37 % done!\n",
      "37 % done!\n",
      "38 % done!\n",
      "38 % done!\n",
      "38 % done!\n",
      "39 % done!\n",
      "39 % done!\n",
      "40 % done!\n",
      "40 % done!\n",
      "41 % done!\n",
      "41 % done!\n",
      "42 % done!\n",
      "42 % done!\n",
      "42 % done!\n",
      "43 % done!\n",
      "43 % done!\n",
      "44 % done!\n",
      "44 % done!\n",
      "45 % done!\n",
      "45 % done!\n",
      "46 % done!\n",
      "46 % done!\n",
      "46 % done!\n",
      "47 % done!\n",
      "47 % done!\n",
      "48 % done!\n",
      "48 % done!\n",
      "49 % done!\n",
      "49 % done!\n",
      "50 % done!\n",
      "50 % done!\n",
      "50 % done!\n",
      "51 % done!\n",
      "51 % done!\n",
      "52 % done!\n",
      "52 % done!\n",
      "53 % done!\n",
      "53 % done!\n",
      "54 % done!\n",
      "54 % done!\n",
      "54 % done!\n",
      "55 % done!\n",
      "55 % done!\n",
      "56 % done!\n",
      "56 % done!\n",
      "57 % done!\n",
      "57 % done!\n",
      "58 % done!\n",
      "58 % done!\n",
      "58 % done!\n",
      "59 % done!\n",
      "59 % done!\n",
      "60 % done!\n",
      "60 % done!\n",
      "61 % done!\n",
      "61 % done!\n",
      "62 % done!\n",
      "62 % done!\n",
      "62 % done!\n",
      "63 % done!\n",
      "63 % done!\n",
      "64 % done!\n",
      "64 % done!\n",
      "65 % done!\n",
      "65 % done!\n",
      "65 % done!\n",
      "66 % done!\n",
      "66 % done!\n",
      "67 % done!\n",
      "67 % done!\n",
      "68 % done!\n",
      "68 % done!\n",
      "69 % done!\n",
      "69 % done!\n",
      "69 % done!\n",
      "70 % done!\n",
      "70 % done!\n",
      "71 % done!\n",
      "71 % done!\n",
      "72 % done!\n",
      "72 % done!\n",
      "73 % done!\n",
      "73 % done!\n",
      "73 % done!\n",
      "74 % done!\n",
      "74 % done!\n",
      "75 % done!\n",
      "75 % done!\n",
      "76 % done!\n",
      "76 % done!\n",
      "77 % done!\n",
      "77 % done!\n",
      "77 % done!\n",
      "78 % done!\n",
      "78 % done!\n",
      "79 % done!\n",
      "79 % done!\n",
      "80 % done!\n",
      "80 % done!\n",
      "81 % done!\n",
      "81 % done!\n",
      "81 % done!\n",
      "82 % done!\n",
      "82 % done!\n",
      "83 % done!\n",
      "83 % done!\n",
      "84 % done!\n",
      "84 % done!\n",
      "85 % done!\n",
      "85 % done!\n",
      "85 % done!\n",
      "86 % done!\n",
      "86 % done!\n",
      "87 % done!\n",
      "87 % done!\n",
      "88 % done!\n",
      "88 % done!\n",
      "88 % done!\n",
      "89 % done!\n",
      "89 % done!\n",
      "90 % done!\n",
      "90 % done!\n",
      "91 % done!\n",
      "91 % done!\n",
      "92 % done!\n",
      "92 % done!\n",
      "92 % done!\n",
      "93 % done!\n",
      "93 % done!\n",
      "94 % done!\n",
      "94 % done!\n",
      "95 % done!\n",
      "95 % done!\n",
      "96 % done!\n",
      "96 % done!\n",
      "96 % done!\n",
      "97 % done!\n",
      "97 % done!\n",
      "98 % done!\n",
      "98 % done!\n",
      "99 % done!\n",
      "99 % done!\n",
      "100 % done!\n"
     ]
    }
   ],
   "source": [
    "#all_bounding_boxes_aoi= mosaic_yoloPred_shp(tiles_dir, labels_dir, ortho_name, xres, yres, tile_size_m, EPSG_code, intile=1, iou_thresh=0.75)\n",
    "# Get list of yolo prediction files (.txt)\n",
    "os.chdir(labels_dir)\n",
    "labels=[]\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    labels.append(labels_dir+\"/\"+file)  \n",
    "# Get list of gtiffs (.tif)\n",
    "os.chdir(tiles_dir)\n",
    "gtiffs=[]\n",
    "for file in glob.glob(\"*.tif\"):\n",
    "    gtiffs.append(tiles_dir+\"/\"+file)  \n",
    "\n",
    "# iterate through each prediction file (.txt) and convert YOLO predictions to shapefile\n",
    "iter_all=0\n",
    "for lab in range(len(labels)):\n",
    "    print(str(round(lab/len(labels)*100))+\" % done!\")\n",
    "    # Define one label file and select the corresponding geotiff image\n",
    "    label_file=labels[lab]\n",
    "    label_file_name=Path(label_file).stem # ortho name\n",
    "    for p in gtiffs:\n",
    "        if Path(p).stem ==label_file_name:\n",
    "            gtiff_file=p\n",
    "\n",
    "    # determing image witdth and height\n",
    "    r = gdal.Open(gtiff_file)\n",
    "    img_width=r.RasterXSize\n",
    "    img_height=r.RasterYSize\n",
    "\n",
    "    # Convert from yolo coordinates to x1, y1, x2, y2,\n",
    "    coords= yolo2xy(label_file, img_width, img_height) # class, x1, y1, x2, y2, probability \n",
    "\n",
    "    # Convert from image to geographical coordinates\n",
    "    ## select tile polygon (from tile index shapefile) that corresponds to the label_file_name\n",
    "    tile_index_path=tiles_dir+\"/\"+ortho_name+\"_tile_index.shp\" # define path to tile index\n",
    "    tile_index=gpd.read_file(tile_index_path) # read tile index shapefile\n",
    "    one_tile=tile_index[tile_index['ID']==label_file_name+\".tif\"] # Select tile in tile_index that has ID equal to label_file_name\n",
    "\n",
    "    ## get tile bounding box geographical coordinates (UTM)\n",
    "    one_tile_XminUTM=one_tile.total_bounds[0]\n",
    "    one_tile_YminUTM=one_tile.total_bounds[1]\n",
    "    one_tile_XmaxUTM=one_tile.total_bounds[2]\n",
    "    one_tile_YmaxUTM=one_tile.total_bounds[3]\n",
    "\n",
    "    ## take inner buffer equal to the buffer_size_m \n",
    "    one_tile_innerB= one_tile\n",
    "    one_tile_innerB['geometry'] = one_tile_innerB.geometry.buffer(-intile)\n",
    "\n",
    "    ## get inner tile bounding boxes\n",
    "    one_tile_inner_XminUTM=one_tile_innerB.total_bounds[0]\n",
    "    one_tile_inner_YminUTM=one_tile_innerB.total_bounds[1]\n",
    "    one_tile_inner_XmaxUTM=one_tile_innerB.total_bounds[2]\n",
    "    one_tile_inner_YmaxUTM=one_tile_innerB.total_bounds[3]\n",
    "\n",
    "    # Now iterate through each bounding box and assign UTM coordinates and create a shapefile\n",
    "    if iter_all==0:\n",
    "        iter=0\n",
    "        for i in coords:\n",
    "            if iter== 0:\n",
    "                # Convert bounding box coordinates from image to geographical coords\n",
    "                X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
    "                Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m\n",
    "                X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
    "                Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m\n",
    "\n",
    "                # skip bounding box if it's centroid is NOT within the inner tile (removing the overlap)\n",
    "                X_UTM= (X1_UTM+X2_UTM)/2\n",
    "                Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
    "                if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
    "                    continue\n",
    "\n",
    "                # Create polygon shape from geographical coords\n",
    "                lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
    "                lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
    "                polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "                crs = {'init': 'epsg:'+EPSG_code}\n",
    "                data= {'class': [i[0]], 'prob': [i[5]]}\n",
    "                bboxes_tile = gpd.GeoDataFrame(data, crs=crs, geometry=[polygon_geom])\n",
    "                #bboxes_tile['class']=i[0]\n",
    "                #bboxes_tile['prob']=i[5]\n",
    "                iter=iter+1\n",
    "\n",
    "            else :\n",
    "                # Convert bounding box coordinates from image to geographical coords\n",
    "                X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
    "                Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m\n",
    "                X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
    "                Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m\n",
    "\n",
    "                # skip bounding box if it's centroid is NOT within the inner tile (removing the overlap)\n",
    "                X_UTM= (X1_UTM+X2_UTM)/2\n",
    "                Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
    "                if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
    "                    continue\n",
    "\n",
    "                # Create polygon shape from geographical coords\n",
    "                lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
    "                lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
    "                polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "                crs = {'init': 'epsg:'+EPSG_code}\n",
    "                data= {'class': [i[0]], 'prob': [i[5]]}\n",
    "                bbox = gpd.GeoDataFrame(data,crs=crs, geometry=[polygon_geom])\n",
    "                #bbox['class']=i[0]\n",
    "                #bbox['prob']=i[5]\n",
    "                # Merge polygons to a single file\n",
    "                bboxes_tile = bboxes_tile.append(bbox)\n",
    "                iter=iter+1\n",
    "\n",
    "        # cleanup boxes (removing overlapping ones)\n",
    "        clean_boxes= cleanUp_boudingBoxes(bboxes_tile, iou_thresh)\n",
    "\n",
    "        # store boxes in a shapefile with all bounding boxes \n",
    "        all_bboxes= clean_boxes\n",
    "        iter_all=iter_all+1\n",
    "\n",
    "    else:\n",
    "        iter=0\n",
    "        for i in coords:\n",
    "            if iter== 0:\n",
    "                # Convert bounding box coordinates from image to geographical coords\n",
    "                X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
    "                Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m\n",
    "                X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
    "                Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m\n",
    "\n",
    "                # skip bounding box if it's centroid is NOT within the inner tile (removing the overlap)\n",
    "                X_UTM= (X1_UTM+X2_UTM)/2\n",
    "                Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
    "                if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
    "                    continue\n",
    "\n",
    "                # Create polygon shape from geographical coords\n",
    "                lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
    "                lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
    "                polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "                crs = {'init': 'epsg:'+EPSG_code}\n",
    "                data= {'class': [i[0]], 'prob': [i[5]]}\n",
    "                bboxes_tile = gpd.GeoDataFrame(data, crs=crs, geometry=[polygon_geom])\n",
    "                #bboxes_tile['class']=i[0]\n",
    "                #bboxes_tile['prob']=i[5]\n",
    "                iter=iter+1\n",
    "            else :\n",
    "                # Convert bounding box coordinates from image to geographical coords\n",
    "                X1_UTM=(i[1]*xres)+one_tile_XminUTM\n",
    "                Y1_UTM=(i[2]*yres)+one_tile_YminUTM+tile_size_m\n",
    "                X2_UTM=(i[3]*xres)+one_tile_XminUTM\n",
    "                Y2_UTM=(i[4]*yres)+one_tile_YminUTM+tile_size_m\n",
    "\n",
    "                # skip bounding box if it's centroid is NOT within the inner tile (removing the overlap)\n",
    "                X_UTM= (X1_UTM+X2_UTM)/2\n",
    "                Y_UTM= (Y1_UTM+Y2_UTM)/2\n",
    "                if X_UTM<one_tile_inner_XminUTM or X_UTM>one_tile_inner_XmaxUTM or Y_UTM<one_tile_inner_YminUTM or Y_UTM>one_tile_inner_YmaxUTM:\n",
    "                    continue\n",
    "\n",
    "                # Create polygon shape from geographical coords\n",
    "                lat_point_list = [Y1_UTM, Y1_UTM, Y2_UTM, Y2_UTM, Y1_UTM]\n",
    "                lon_point_list = [X1_UTM, X2_UTM, X2_UTM, X1_UTM, X1_UTM]\n",
    "                polygon_geom = Polygon(zip(lon_point_list, lat_point_list))\n",
    "                crs = {'init': 'epsg:'+EPSG_code}\n",
    "                data= {'class': [i[0]], 'prob': [i[5]]}\n",
    "                bbox = gpd.GeoDataFrame(data,crs=crs, geometry=[polygon_geom])\n",
    "                #bbox['class']=i[0]\n",
    "                #bbox['prob']=i[5]\n",
    "                # Merge polygons to a single file\n",
    "                bboxes_tile = bboxes_tile.append(bbox)\n",
    "                iter=iter+1\n",
    "\n",
    "        # cleanup boxes (removing overlapping ones)\n",
    "        clean_boxes=cleanUp_boudingBoxes(bboxes_tile, iou_thresh)\n",
    "\n",
    "        # store boxes in a shapefile with all bounding boxes \n",
    "        all_bboxes = all_bboxes.append(clean_boxes)\n",
    "        iter_all=iter_all+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f491c498",
   "metadata": {},
   "source": [
    "Export final shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63940165",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bboxes.to_file(ortho_folder_path+'/predictions.shp', driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bfe82f",
   "metadata": {},
   "source": [
    "# 6 - Cleanup environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d478cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete prediction folder\n",
    "shutil.rmtree(tiles_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677fda54",
   "metadata": {},
   "source": [
    "# End! (unless one wants to summarize the results beyond the boundign box predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d118a1",
   "metadata": {},
   "source": [
    "# 7 - create PDF report (?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:yolov5]",
   "language": "python",
   "name": "conda-env-yolov5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
